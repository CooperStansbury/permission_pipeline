{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERSION:  3.7.3\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(\"VERSION: \", python_version()) # expect 3.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.24.3) or chardet (2.3.0) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# data science standards\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n",
    "from matplotlib.pyplot import figure\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# keras/tensorflow\n",
    "from tensorflow.metrics import auc as tf_auc\n",
    "from tensorflow import local_variables_initializer\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Conv2D, \\\n",
    "        MaxPooling1D, LSTM, Flatten, BatchNormalization,Embedding,Reshape, Dropout\n",
    "\n",
    "\n",
    "# Local custom data loading functions\n",
    "import load_data\n",
    "import clean_data\n",
    "import custom_feature_extraction\n",
    "import custom_keras_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirty spaCy error workaround:\n",
    "get_ipython().config.get('IPKernelApp', {})['parent_appname'] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load annoations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation</th>\n",
       "      <th>fileID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>1</td>\n",
       "      <td>a copy of this entire consent form will be giv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>permission_statement</td>\n",
       "      <td>1</td>\n",
       "      <td>i give my permission for photographs/audio/vid...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>1</td>\n",
       "      <td>language for required recordings: the research...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>1</td>\n",
       "      <td>\"(if applicable, add) information about indivi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>1</td>\n",
       "      <td>this consent form will be filed securely in an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  annotation fileID  \\\n",
       "0  NON_permission_statement.      1   \n",
       "1       permission_statement      1   \n",
       "2  NON_permission_statement.      1   \n",
       "3  NON_permission_statement.      1   \n",
       "4  NON_permission_statement.      1   \n",
       "\n",
       "                                                text  label  \n",
       "0  a copy of this entire consent form will be giv...      0  \n",
       "1  i give my permission for photographs/audio/vid...      1  \n",
       "2  language for required recordings: the research...      0  \n",
       "3  \"(if applicable, add) information about indivi...      0  \n",
       "4  this consent form will be filed securely in an...      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations ='../data/Annotations04-09-19.json'\n",
    "df = load_data.getJSONData(annotations)\n",
    "\n",
    "to  = 'label'\n",
    "field = 'annotation'\n",
    "df[to] = df.apply(lambda row:clean_data.convertAnnotationtoBinary(row, field), axis =1)   \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean sentence length: 160.88580168238593\n",
      "std sentence length: 114.46874256211423\n",
      "max sentence length: 1961\n",
      "min sentence length: 7\n"
     ]
    }
   ],
   "source": [
    "df['sent_len'] = df['text'].apply(len)\n",
    "\n",
    "print('mean sentence length:', df['sent_len'].mean())\n",
    "print('std sentence length:', df['sent_len'].std())\n",
    "print('max sentence length:', df['sent_len'].max())\n",
    "print('min sentence length:', df['sent_len'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10360\n"
     ]
    }
   ],
   "source": [
    "uniques = set()\n",
    "df['text'].str.lower().str.split().apply(uniques.update)\n",
    "\n",
    "print(len(uniques))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "slim2 = df[['label', 'text']] # subset dataframe to make it easier to work with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Functionalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 8000\n",
    "maxlen = 400\n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocabulary_size)\n",
    "tokenizer.fit_on_texts(slim2['text'])\n",
    "sequences = tokenizer.texts_to_sequences(slim2['text'])\n",
    "data = pad_sequences(sequences, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "slim2['data'] = data.tolist()\n",
    "# slim2['data'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col_names = ['seq_posi' + str(i) for i in range(0,maxlen)]\n",
    "pos_seq_df = pd.DataFrame(slim2['data'].values.tolist(), columns=new_col_names)\n",
    "slim2 = pd.concat([slim2, pos_seq_df], axis=1)\n",
    "# slim2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train, text_test = train_test_split(slim2,\n",
    "                               stratify=slim2['label'],\n",
    "                               test_size=0.3, \n",
    "                               random_state=1729)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Labels to Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = keras.utils.to_categorical(text_train['label'], num_classes=2)\n",
    "label_test = keras.utils.to_categorical(text_test['label'], num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "dtBase = DecisionTreeClassifier(max_depth=10, \n",
    "                               max_features=9,\n",
    "                               class_weight={1:.2})\n",
    "\n",
    "models.append((\"DecisionTree\",dtBase))\n",
    "\n",
    "rdfBase = RandomForestClassifier(n_estimators=1000,\n",
    "                                class_weight={1:.2})\n",
    "\n",
    "models.append((\"RandomForest\",rdfBase))\n",
    "\n",
    "models.append((\"SVM\",SVC(gamma='auto')))\n",
    "models.append((\"LogisticRegression\", LogisticRegression(solver='liblinear',\n",
    "                                  max_iter=1000,\n",
    "                                  penalty='l1')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_models = []\n",
    "new_rows = []\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(text_train[new_col_names], text_train['label'])\n",
    "    fitted_models.append((name, model))\n",
    "    prediction_vec = model.predict(text_test[new_col_names])\n",
    "    row = {\n",
    "        'Model:': name,\n",
    "        'Accuracy:': accuracy_score(text_test['label'], prediction_vec),\n",
    "        'Precision:': precision_score(text_test['label'], prediction_vec),\n",
    "        'ROC:': roc_auc_score(text_test['label'], prediction_vec)\n",
    "    }\n",
    "    \n",
    "    new_rows.append(row)\n",
    "\n",
    "baseline_results_df = pd.DataFrame(new_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model:</th>\n",
       "      <th>Accuracy:</th>\n",
       "      <th>Precision:</th>\n",
       "      <th>ROC:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.763806</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.496705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.792693</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.550695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.796092</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.547433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.768054</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.504885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Majority Class Classifier</td>\n",
       "      <td>0.777400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model:  Accuracy:  Precision:      ROC:\n",
       "0                     DecisionTree   0.763806    0.166667  0.496705\n",
       "1                     RandomForest   0.792693    0.714286  0.550695\n",
       "2                              SVM   0.796092    0.866667  0.547433\n",
       "3               LogisticRegression   0.768054    0.296296  0.504885\n",
       "4  Naive Majority Class Classifier   0.777400    0.000000  0.500000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive baseline\n",
    "majority_class = np.zeros(len(text_test['label']))\n",
    "\n",
    "count = len(baseline_results_df)\n",
    "\n",
    "ac = accuracy_score(text_test['label'], majority_class)\n",
    "pr = precision_score(text_test['label'], majority_class)\n",
    "roc = roc_auc_score(text_test['label'], majority_class)\n",
    "\n",
    "baseline_results_df.loc[count, 'Model:'] = 'Naive Majority Class Classifier'\n",
    "baseline_results_df.loc[count, 'Accuracy:'] = ac\n",
    "baseline_results_df.loc[count, 'Precision:'] = pr\n",
    "baseline_results_df.loc[count, 'ROC:'] = roc\n",
    "\n",
    "cols = ['Model:', 'Accuracy:', 'Precision:', 'ROC:']\n",
    "\n",
    "baseline_results_df = baseline_results_df[cols]\n",
    "baseline_results_df.head(len(baseline_results_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "to_shuffle = True\n",
    "n_batch = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN-LTSM (Model 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:526: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:788: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 2746 samples, validate on 1177 samples\n",
      "Epoch 1/5\n",
      "2746/2746 [==============================] - 90s 33ms/step - loss: 0.4170 - acc: 0.8241 - keras_precision: 0.8241 - keras_recall: 0.8241 - keras_auc: 0.8339 - val_loss: 0.3197 - val_acc: 0.8581 - val_keras_precision: 0.8581 - val_keras_recall: 0.8581 - val_keras_auc: 0.8999\n",
      "Epoch 2/5\n",
      "2746/2746 [==============================] - 89s 32ms/step - loss: 0.2223 - acc: 0.9155 - keras_precision: 0.9155 - keras_recall: 0.9155 - keras_auc: 0.9262 - val_loss: 0.3517 - val_acc: 0.8488 - val_keras_precision: 0.8488 - val_keras_recall: 0.8488 - val_keras_auc: 0.9366\n",
      "Epoch 3/5\n",
      "2746/2746 [==============================] - 88s 32ms/step - loss: 0.1301 - acc: 0.9516 - keras_precision: 0.9516 - keras_recall: 0.9516 - keras_auc: 0.9462 - val_loss: 0.4106 - val_acc: 0.8581 - val_keras_precision: 0.8581 - val_keras_recall: 0.8581 - val_keras_auc: 0.9522\n",
      "Epoch 4/5\n",
      "2746/2746 [==============================] - 89s 32ms/step - loss: 0.0649 - acc: 0.9771 - keras_precision: 0.9771 - keras_recall: 0.9771 - keras_auc: 0.9574 - val_loss: 0.4826 - val_acc: 0.8428 - val_keras_precision: 0.8428 - val_keras_recall: 0.8428 - val_keras_auc: 0.9612\n",
      "Epoch 5/5\n",
      "2746/2746 [==============================] - 88s 32ms/step - loss: 0.0421 - acc: 0.9865 - keras_precision: 0.9865 - keras_recall: 0.9865 - keras_auc: 0.9637 - val_loss: 0.6191 - val_acc: 0.8411 - val_keras_precision: 0.8411 - val_keras_recall: 0.8411 - val_keras_auc: 0.9657\n"
     ]
    }
   ],
   "source": [
    "cnn_1 = Sequential()\n",
    "cnn_1.add(Embedding(vocabulary_size, 100, input_length=maxlen))\n",
    "cnn_1.add(Dropout(0.2))\n",
    "cnn_1.add(Conv1D(64, 5, activation='relu'))\n",
    "cnn_1.add(MaxPooling1D(pool_size=4))\n",
    "cnn_1.add(LSTM(100))\n",
    "cnn_1.add(Dense(2, activation='softmax'))\n",
    "cnn_1.compile(loss='binary_crossentropy', \n",
    "               optimizer='adam', \n",
    "                metrics=['accuracy', \n",
    "                    custom_keras_metrics.keras_precision, \n",
    "                    custom_keras_metrics.keras_recall, \n",
    "                    custom_keras_metrics.keras_auc])\n",
    "\n",
    "fit_cnn_1 = cnn_1.fit(text_train[new_col_names], \n",
    "                  label_train, \n",
    "                  validation_data=(text_test[new_col_names],label_test), \n",
    "                  epochs=n_epochs,\n",
    "                  shuffle=to_shuffle,\n",
    "                  batch_size=3)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 2 - Without LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2746 samples, validate on 1177 samples\n",
      "Epoch 1/5\n",
      "2746/2746 [==============================] - 10s 4ms/step - loss: 0.4464 - acc: 0.8074 - keras_precision: 0.8074 - keras_recall: 0.8074 - keras_auc: 0.8097 - val_loss: 0.3428 - val_acc: 0.8607 - val_keras_precision: 0.8607 - val_keras_recall: 0.8607 - val_keras_auc: 0.8872\n",
      "Epoch 2/5\n",
      "2746/2746 [==============================] - 10s 4ms/step - loss: 0.2117 - acc: 0.9151 - keras_precision: 0.9151 - keras_recall: 0.9151 - keras_auc: 0.9171 - val_loss: 0.3957 - val_acc: 0.8632 - val_keras_precision: 0.8632 - val_keras_recall: 0.8632 - val_keras_auc: 0.9322\n",
      "Epoch 3/5\n",
      "2746/2746 [==============================] - 10s 4ms/step - loss: 0.0976 - acc: 0.9629 - keras_precision: 0.9629 - keras_recall: 0.9629 - keras_auc: 0.9438 - val_loss: 0.4542 - val_acc: 0.8471 - val_keras_precision: 0.8471 - val_keras_recall: 0.8471 - val_keras_auc: 0.9516\n",
      "Epoch 4/5\n",
      "2746/2746 [==============================] - 10s 4ms/step - loss: 0.0390 - acc: 0.9894 - keras_precision: 0.9894 - keras_recall: 0.9894 - keras_auc: 0.9570 - val_loss: 0.6191 - val_acc: 0.8539 - val_keras_precision: 0.8539 - val_keras_recall: 0.8539 - val_keras_auc: 0.9611\n",
      "Epoch 5/5\n",
      "2746/2746 [==============================] - 10s 4ms/step - loss: 0.0360 - acc: 0.9916 - keras_precision: 0.9916 - keras_recall: 0.9916 - keras_auc: 0.9634 - val_loss: 0.6073 - val_acc: 0.8513 - val_keras_precision: 0.8513 - val_keras_recall: 0.8513 - val_keras_auc: 0.9659\n"
     ]
    }
   ],
   "source": [
    "cnn_2 = Sequential()\n",
    "cnn_2.add(Embedding(vocabulary_size, 100, input_length=maxlen))\n",
    "cnn_2.add(Dropout(0.2))\n",
    "cnn_2.add(Conv1D(64, 5, activation='relu'))\n",
    "cnn_2.add(MaxPooling1D(pool_size=4))\n",
    "cnn_2.add(Flatten())\n",
    "cnn_2.add(Dense(2, activation='softmax'))\n",
    "cnn_2.compile(loss='binary_crossentropy', \n",
    "               optimizer='adam', \n",
    "                metrics=['accuracy', \n",
    "                    custom_keras_metrics.keras_precision, \n",
    "                    custom_keras_metrics.keras_recall, \n",
    "                    custom_keras_metrics.keras_auc])\n",
    "\n",
    "fit_cnn_2 = cnn_2.fit(text_train[new_col_names], \n",
    "                  label_train, \n",
    "                  validation_data=(text_test[new_col_names],label_test), \n",
    "                  epochs=n_epochs,\n",
    "                  shuffle=to_shuffle,\n",
    "                  batch_size=n_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 3 - LSTM without Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2746 samples, validate on 1177 samples\n",
      "Epoch 1/5\n",
      "2746/2746 [==============================] - 351s 128ms/step - loss: 0.4214 - acc: 0.8194 - keras_precision: 0.8194 - keras_recall: 0.8194 - keras_auc: 0.8399 - val_loss: 0.3177 - val_acc: 0.8717 - val_keras_precision: 0.8717 - val_keras_recall: 0.8717 - val_keras_auc: 0.8980\n",
      "Epoch 2/5\n",
      "2746/2746 [==============================] - 352s 128ms/step - loss: 0.2361 - acc: 0.9079 - keras_precision: 0.9079 - keras_recall: 0.9079 - keras_auc: 0.9230 - val_loss: 0.3598 - val_acc: 0.8709 - val_keras_precision: 0.8709 - val_keras_recall: 0.8709 - val_keras_auc: 0.9335\n",
      "Epoch 3/5\n",
      "2746/2746 [==============================] - 353s 129ms/step - loss: 0.1550 - acc: 0.9406 - keras_precision: 0.9406 - keras_recall: 0.9406 - keras_auc: 0.9426 - val_loss: 0.3779 - val_acc: 0.8573 - val_keras_precision: 0.8573 - val_keras_recall: 0.8573 - val_keras_auc: 0.9484\n",
      "Epoch 4/5\n",
      "2746/2746 [==============================] - 425s 155ms/step - loss: 0.0944 - acc: 0.9643 - keras_precision: 0.9643 - keras_recall: 0.9643 - keras_auc: 0.9542 - val_loss: 0.4504 - val_acc: 0.8377 - val_keras_precision: 0.8377 - val_keras_recall: 0.8377 - val_keras_auc: 0.9575\n",
      "Epoch 5/5\n",
      "2746/2746 [==============================] - 419s 153ms/step - loss: 0.0697 - acc: 0.9760 - keras_precision: 0.9760 - keras_recall: 0.9760 - keras_auc: 0.9605 - val_loss: 0.5585 - val_acc: 0.8505 - val_keras_precision: 0.8505 - val_keras_recall: 0.8505 - val_keras_auc: 0.9621\n"
     ]
    }
   ],
   "source": [
    "cnn_3 = Sequential()\n",
    "cnn_3.add(Embedding(vocabulary_size, 100, input_length=maxlen))\n",
    "cnn_3.add(Dropout(0.2))\n",
    "cnn_3.add(LSTM(100))\n",
    "cnn_3.add(Dense(2, activation='softmax'))\n",
    "cnn_3.compile(loss='binary_crossentropy', \n",
    "               optimizer='adam', \n",
    "                metrics=['accuracy', \n",
    "                    custom_keras_metrics.keras_precision, \n",
    "                    custom_keras_metrics.keras_recall, \n",
    "                    custom_keras_metrics.keras_auc])\n",
    "\n",
    "fit_cnn_3 = cnn_3.fit(text_train[new_col_names], \n",
    "                  label_train, \n",
    "                  validation_data=(text_test[new_col_names],label_test), \n",
    "                  epochs=n_epochs,\n",
    "                  shuffle=to_shuffle,\n",
    "                  batch_size=n_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2746 samples, validate on 1177 samples\n",
      "Epoch 1/5\n",
      "2746/2746 [==============================] - 9s 3ms/step - loss: 0.5333 - acc: 0.7771 - keras_precision: 0.7771 - keras_recall: 0.7771 - keras_auc: 0.7659 - val_loss: 0.5303 - val_acc: 0.7774 - val_keras_precision: 0.7774 - val_keras_recall: 0.7774 - val_keras_auc: 0.7684\n",
      "Epoch 2/5\n",
      "2746/2746 [==============================] - 8s 3ms/step - loss: 0.5306 - acc: 0.7775 - keras_precision: 0.7775 - keras_recall: 0.7775 - keras_auc: 0.7709 - val_loss: 0.5304 - val_acc: 0.7774 - val_keras_precision: 0.7774 - val_keras_recall: 0.7774 - val_keras_auc: 0.7727\n",
      "Epoch 3/5\n",
      "2746/2746 [==============================] - 7s 3ms/step - loss: 0.5301 - acc: 0.7775 - keras_precision: 0.7775 - keras_recall: 0.7775 - keras_auc: 0.7752 - val_loss: 0.5311 - val_acc: 0.7774 - val_keras_precision: 0.7774 - val_keras_recall: 0.7774 - val_keras_auc: 0.7746\n",
      "Epoch 4/5\n",
      "2746/2746 [==============================] - 6s 2ms/step - loss: 0.5303 - acc: 0.7775 - keras_precision: 0.7775 - keras_recall: 0.7775 - keras_auc: 0.7750 - val_loss: 0.5301 - val_acc: 0.7774 - val_keras_precision: 0.7774 - val_keras_recall: 0.7774 - val_keras_auc: 0.7757\n",
      "Epoch 5/5\n",
      "2746/2746 [==============================] - 7s 3ms/step - loss: 0.5299 - acc: 0.7775 - keras_precision: 0.7775 - keras_recall: 0.7775 - keras_auc: 0.7769 - val_loss: 0.5302 - val_acc: 0.7774 - val_keras_precision: 0.7774 - val_keras_recall: 0.7774 - val_keras_auc: 0.7766\n"
     ]
    }
   ],
   "source": [
    "dim = text_train[new_col_names].shape[1]\n",
    "\n",
    "auto_encoder_1 = Sequential()\n",
    "auto_encoder_1.add(Dense(units=100, activation='relu', input_dim=dim))\n",
    "auto_encoder_1.add(Dense(units=500, activation='softmax'))\n",
    "auto_encoder_1.add(Dense(units=10, activation='softmax'))\n",
    "auto_encoder_1.add(Dense(units=1000, activation='relu'))\n",
    "auto_encoder_1.add(Dense(units=500, activation='relu'))\n",
    "auto_encoder_1.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "auto_encoder_1.compile(loss='binary_crossentropy',\n",
    "              optimizer=keras.optimizers.Adagrad(lr=0.001), \n",
    "              metrics=['accuracy', \n",
    "                       custom_keras_metrics.keras_precision, \n",
    "                       custom_keras_metrics.keras_recall, \n",
    "                       custom_keras_metrics.keras_auc])\n",
    "\n",
    "fit_auto_encoder_1 = auto_encoder_1.fit(text_train[new_col_names], \n",
    "                  label_train, \n",
    "                  validation_data=(text_test[new_col_names],label_test), \n",
    "                epochs=n_epochs,\n",
    "                batch_size=n_batch,\n",
    "                shuffle=to_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_1.name = \"cnn_1\"\n",
    "cnn_2.name = \"cnn_2\"\n",
    "cnn_3.name = \"cnn_3\"\n",
    "auto_encoder_1.name = \"auto_encoder_1\"\n",
    "ann_models = [cnn_1, cnn_2, cnn_3, auto_encoder_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model in ann_models:\n",
    "#     print(\"##########################\", model.name, \"##########################\")\n",
    "#     print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy:</th>\n",
       "      <th>Model:</th>\n",
       "      <th>Precision:</th>\n",
       "      <th>ROC:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.841122</td>\n",
       "      <td>cnn_1</td>\n",
       "      <td>0.841122</td>\n",
       "      <td>0.965662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.851317</td>\n",
       "      <td>cnn_2</td>\n",
       "      <td>0.851317</td>\n",
       "      <td>0.965937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.850467</td>\n",
       "      <td>cnn_3</td>\n",
       "      <td>0.850467</td>\n",
       "      <td>0.962065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.777400</td>\n",
       "      <td>auto_encoder_1</td>\n",
       "      <td>0.777400</td>\n",
       "      <td>0.776551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy:          Model:  Precision:      ROC:\n",
       "0   0.841122           cnn_1    0.841122  0.965662\n",
       "1   0.851317           cnn_2    0.851317  0.965937\n",
       "2   0.850467           cnn_3    0.850467  0.962065\n",
       "3   0.777400  auto_encoder_1    0.777400  0.776551"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rows = []\n",
    "\n",
    "for model in ann_models:  \n",
    "    row = {\"Model:\": model.name, \n",
    "           \"Precision:\": model.history.history['val_keras_precision'][-1],\n",
    "           \"Accuracy:\": model.history.history['val_acc'][-1],\n",
    "           \"ROC:\": model.history.history['val_keras_auc'][-1],}\n",
    "        \n",
    "    new_rows.append(row) \n",
    "        \n",
    "ann_results_df = pd.DataFrame(new_rows)\n",
    "ann_results_df.head(len(ann_results_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model:</th>\n",
       "      <th>Accuracy:</th>\n",
       "      <th>Precision:</th>\n",
       "      <th>ROC:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.763806</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.496705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.792693</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.550695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.796092</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.547433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.768054</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.504885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Majority Class Classifier</td>\n",
       "      <td>0.777400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cnn_1</td>\n",
       "      <td>0.841122</td>\n",
       "      <td>0.841122</td>\n",
       "      <td>0.965662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cnn_2</td>\n",
       "      <td>0.851317</td>\n",
       "      <td>0.851317</td>\n",
       "      <td>0.965937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cnn_3</td>\n",
       "      <td>0.850467</td>\n",
       "      <td>0.850467</td>\n",
       "      <td>0.962065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>auto_encoder_1</td>\n",
       "      <td>0.777400</td>\n",
       "      <td>0.777400</td>\n",
       "      <td>0.776551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model:  Accuracy:  Precision:      ROC:\n",
       "0                     DecisionTree   0.763806    0.166667  0.496705\n",
       "1                     RandomForest   0.792693    0.714286  0.550695\n",
       "2                              SVM   0.796092    0.866667  0.547433\n",
       "3               LogisticRegression   0.768054    0.296296  0.504885\n",
       "4  Naive Majority Class Classifier   0.777400    0.000000  0.500000\n",
       "0                            cnn_1   0.841122    0.841122  0.965662\n",
       "1                            cnn_2   0.851317    0.851317  0.965937\n",
       "2                            cnn_3   0.850467    0.850467  0.962065\n",
       "3                   auto_encoder_1   0.777400    0.777400  0.776551"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.concat([baseline_results_df, ann_results_df])\n",
    "cols = ['Model:', 'Accuracy:', 'Precision:', 'ROC:']\n",
    "results_df = results_df[cols]\n",
    "results_df.head(len(results_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Prections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation</th>\n",
       "      <th>fileID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>1</td>\n",
       "      <td>a copy of this entire consent form will be giv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NON_permission_statement</td>\n",
       "      <td>1</td>\n",
       "      <td>\"what if i change my mind about participating ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NON_permission_statement</td>\n",
       "      <td>1</td>\n",
       "      <td>ask your study doctor for more information abo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NON_permission_statement</td>\n",
       "      <td>1</td>\n",
       "      <td>newborn screening required additional language...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NON_permission_statement</td>\n",
       "      <td>1</td>\n",
       "      <td>\"if you are a healthy volunteer, no direct med...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  annotation fileID  \\\n",
       "0  NON_permission_statement.      1   \n",
       "1   NON_permission_statement      1   \n",
       "2   NON_permission_statement      1   \n",
       "3   NON_permission_statement      1   \n",
       "4   NON_permission_statement      1   \n",
       "\n",
       "                                                text  \n",
       "0  a copy of this entire consent form will be giv...  \n",
       "1  \"what if i change my mind about participating ...  \n",
       "2  ask your study doctor for more information abo...  \n",
       "3  newborn screening required additional language...  \n",
       "4  \"if you are a healthy volunteer, no direct med...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data ='../data/ALL_CANDIDATES.json'\n",
    "pred_df = load_data.getJSONData(full_data)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the same vocab an maxlen \n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocabulary_size)\n",
    "tokenizer.fit_on_texts(pred_df['text'])\n",
    "sequences = tokenizer.texts_to_sequences(pred_df['text'])\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "pred_df['data'] = data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col_names = ['seq_posi' + str(i) for i in range(0,maxlen)]\n",
    "pos_seq_df = pd.DataFrame(pred_df['data'].values.tolist(), columns=new_col_names)\n",
    "pred_df = pd.concat([pred_df, pos_seq_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN-LTSM Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cnn_1.predict_classes(pred_df[new_col_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability = cnn_1.predict_proba(pred_df[new_col_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9967885e-01 3.2119456e-04]\n",
      " [1.0437470e-02 9.8956257e-01]\n",
      " [9.9415672e-01 5.8432948e-03]\n",
      " [9.9999356e-01 6.3821085e-06]\n",
      " [9.9998438e-01 1.5575710e-05]\n",
      " [9.9987209e-01 1.2794412e-04]\n",
      " [9.9985158e-01 1.4840256e-04]\n",
      " [9.9822062e-01 1.7793432e-03]\n",
      " [9.9289715e-01 7.1027805e-03]\n",
      " [9.9801528e-01 1.9846889e-03]]\n",
      "[0 1 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(probability[:10])\n",
    "print(predictions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_permission = []\n",
    "for px_NOT_permission, px_permission in probability:\n",
    "#     print(format(px_NOT_permission, 'f'), format(px_permission, 'f'))\n",
    "    proba_permission.append(format(px_permission, 'f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "20000\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "print(len(pred_df))\n",
    "print(len(predictions))\n",
    "print(len(proba_permission))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Positive Predictions: 3060\n",
      "Number of Cases: 20000\n",
      "Percentage Predicted Positive:  0.153\n"
     ]
    }
   ],
   "source": [
    "print('Total Positive Predictions:', sum(predictions))\n",
    "print('Number of Cases:', len(predictions))\n",
    "print('Percentage Predicted Positive: ', sum(predictions)/len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['annotation', 'fileID', 'text', 'data', 'prediction', 'probability_permission']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation</th>\n",
       "      <th>fileID</th>\n",
       "      <th>text</th>\n",
       "      <th>data</th>\n",
       "      <th>prediction</th>\n",
       "      <th>probability_permission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>1</td>\n",
       "      <td>a copy of this entire consent form will be giv...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NON_permission_statement</td>\n",
       "      <td>1</td>\n",
       "      <td>\"what if i change my mind about participating ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NON_permission_statement</td>\n",
       "      <td>1</td>\n",
       "      <td>ask your study doctor for more information abo...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NON_permission_statement</td>\n",
       "      <td>1</td>\n",
       "      <td>newborn screening required additional language...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NON_permission_statement</td>\n",
       "      <td>1</td>\n",
       "      <td>\"if you are a healthy volunteer, no direct med...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  annotation fileID  \\\n",
       "0  NON_permission_statement.      1   \n",
       "1   NON_permission_statement      1   \n",
       "2   NON_permission_statement      1   \n",
       "3   NON_permission_statement      1   \n",
       "4   NON_permission_statement      1   \n",
       "\n",
       "                                                text  \\\n",
       "0  a copy of this entire consent form will be giv...   \n",
       "1  \"what if i change my mind about participating ...   \n",
       "2  ask your study doctor for more information abo...   \n",
       "3  newborn screening required additional language...   \n",
       "4  \"if you are a healthy volunteer, no direct med...   \n",
       "\n",
       "                                                data  prediction  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...           0   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...           1   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...           0   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...           0   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...           0   \n",
       "\n",
       "  probability_permission  \n",
       "0               0.000321  \n",
       "1               0.989563  \n",
       "2               0.005843  \n",
       "3               0.000006  \n",
       "4               0.000016  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df['prediction'] = predictions\n",
    "pred_df['probability_permission'] = proba_permission\n",
    "\n",
    "cols_to_keep = [c for c in pred_df.columns if not c.__contains__('seq_posi')]\n",
    "print(cols_to_keep)\n",
    "\n",
    "slim_pred_df = pred_df[cols_to_keep]\n",
    "\n",
    "slim_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "annotation                object\n",
       "fileID                    object\n",
       "text                      object\n",
       "data                      object\n",
       "prediction                 int64\n",
       "probability_permission    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slim_pred_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# slim_pred_df.to_numeric(slim_pred_df['probability_permission'])\n",
    "slim_pred_df[\"probability_permission\"] = slim_pred_df['probability_permission'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all positive predictions\n",
    "positives_df = slim_pred_df.loc[slim_pred_df['probability_permission'] >= .9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"will there be any discomfort, is any anaesthetic needed if you are having an intimate examination the staff will describe the procedure to you, and your verbal consent for this will be obtained.\" \n",
      "\n",
      "the [blood/tissue/genetic information/medical information] will be labeled as described below. \n",
      "\n",
      "\"by agreeing to be in this repository, you are giving permission (also called authorization) for us to use and disclose your health information as described in this form.\" \n",
      "\n",
      "\"a copy of this signed consent document, information about this study and the results of any test or procedure done may be included in my medical record and may be seen by my insurance company.  \" \n",
      "\n",
      ": 12/21/2015 continue to use and disclose your/your child s health information for research as described in this form. \n",
      "\n",
      "\"we will get this information from your health care providers such as [name record holders if known, e.g.: uw health].\" \n",
      "\n",
      "the research team will know your identity and that you are in the research study. \n",
      "\n",
      "i do not want the patient s records to be reviewed for research and i do not want the patient or me to be contacted about research(initials). \n",
      "\n",
      "\"my decision to not participate, or to withdraw from the study will not affect my future care or status with this investigator.\" \n",
      "\n",
      "my doctor has provided a copy of the information from the company that makes this device and has reviewed that information with me. \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_predictions_df = positives_df.sample(10)\n",
    "\n",
    "[print(text, \"\\n\") for text in sample_predictions_df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
