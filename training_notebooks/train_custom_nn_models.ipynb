{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "print(\"VERSION: \", python_version()) # expect 3.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data science standards\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n",
    "from matplotlib.pyplot import figure\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# keras/tensorflow\n",
    "from tensorflow.metrics import auc as tf_auc\n",
    "from tensorflow import local_variables_initializer\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Conv2D, \\\n",
    "        MaxPooling1D, LSTM, Flatten, BatchNormalization,Embedding,Reshape, Dropout\n",
    "\n",
    "\n",
    "# Local custom data loading functions\n",
    "import load_data\n",
    "import clean_data\n",
    "import custom_feature_extraction\n",
    "import custom_keras_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirty spaCy error workaround:\n",
    "get_ipython().config.get('IPKernelApp', {})['parent_appname'] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load annoations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation</th>\n",
       "      <th>fileID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>1</td>\n",
       "      <td>a copy of this entire consent form will be giv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>permission_statement</td>\n",
       "      <td>1</td>\n",
       "      <td>i give my permission for photographs/audio/vid...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>1</td>\n",
       "      <td>language for required recordings: the research...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>1</td>\n",
       "      <td>\"(if applicable, add) information about indivi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>1</td>\n",
       "      <td>this consent form will be filed securely in an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  annotation fileID  \\\n",
       "0  NON_permission_statement.      1   \n",
       "1       permission_statement      1   \n",
       "2  NON_permission_statement.      1   \n",
       "3  NON_permission_statement.      1   \n",
       "4  NON_permission_statement.      1   \n",
       "\n",
       "                                                text  label  \n",
       "0  a copy of this entire consent form will be giv...      0  \n",
       "1  i give my permission for photographs/audio/vid...      1  \n",
       "2  language for required recordings: the research...      0  \n",
       "3  \"(if applicable, add) information about indivi...      0  \n",
       "4  this consent form will be filed securely in an...      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations ='../data/Annotations04-09-19.json'\n",
    "df = load_data.getJSONData(annotations)\n",
    "\n",
    "to  = 'label'\n",
    "field = 'annotation'\n",
    "df[to] = df.apply(lambda row:clean_data.convertAnnotationtoBinary(row, field), axis =1)   \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "slim2 = df[['label', 'text']] # subset dataframe to make it easier to work with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Functionalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 1000\n",
    "maxlen = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "tokenizer.fit_on_texts(slim2['text'])\n",
    "sequences = tokenizer.texts_to_sequences(slim2['text'])\n",
    "data = pad_sequences(sequences, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "slim2['data'] = data.tolist()\n",
    "# slim2['data'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col_names = ['seq_posi' + str(i) for i in range(0,maxlen)]\n",
    "pos_seq_df = pd.DataFrame(slim2['data'].values.tolist(), columns=new_col_names)\n",
    "slim2 = pd.concat([slim2, pos_seq_df], axis=1)\n",
    "# slim2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train, text_test = train_test_split(slim2,\n",
    "                               stratify=slim2['label'],\n",
    "                               test_size=0.3, \n",
    "                               random_state=1729)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Labels to Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = keras.utils.to_categorical(text_train['label'], num_classes=2)\n",
    "label_test = keras.utils.to_categorical(text_test['label'], num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "dtBase = DecisionTreeClassifier(max_depth=10, \n",
    "                               max_features=9,\n",
    "                               class_weight={1:.2})\n",
    "\n",
    "models.append((\"DecisionTree\",dtBase))\n",
    "\n",
    "rdfBase = RandomForestClassifier(n_estimators=1000,\n",
    "                                class_weight={1:.2})\n",
    "\n",
    "models.append((\"RandomForest\",rdfBase))\n",
    "\n",
    "models.append((\"SVM\",SVC(gamma='auto')))\n",
    "models.append((\"LogisticRegression\", LogisticRegression(solver='liblinear',\n",
    "                                  max_iter=1000,\n",
    "                                  penalty='l1')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_models = []\n",
    "new_rows = []\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(text_train[new_col_names], text_train['label'])\n",
    "    fitted_models.append((name, model))\n",
    "    prediction_vec = model.predict(text_test[new_col_names])\n",
    "    row = {\n",
    "        'Model:': name,\n",
    "        'Accuracy:': accuracy_score(text_test['label'], prediction_vec),\n",
    "        'Precision:': precision_score(text_test['label'], prediction_vec),\n",
    "        'ROC:': roc_auc_score(text_test['label'], prediction_vec)\n",
    "    }\n",
    "    \n",
    "    new_rows.append(row)\n",
    "\n",
    "baseline_results_df = pd.DataFrame(new_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model:</th>\n",
       "      <th>Accuracy:</th>\n",
       "      <th>Precision:</th>\n",
       "      <th>ROC:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.768904</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.502707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.786746</td>\n",
       "      <td>0.603774</td>\n",
       "      <td>0.549593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.796092</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.547433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.772302</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.504893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Majority Class Classifier</td>\n",
       "      <td>0.777400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model:  Accuracy:  Precision:      ROC:\n",
       "0                     DecisionTree   0.768904    0.272727  0.502707\n",
       "1                     RandomForest   0.786746    0.603774  0.549593\n",
       "2                              SVM   0.796092    0.866667  0.547433\n",
       "3               LogisticRegression   0.772302    0.333333  0.504893\n",
       "4  Naive Majority Class Classifier   0.777400    0.000000  0.500000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive baseline\n",
    "majority_class = np.zeros(len(text_test['label']))\n",
    "\n",
    "count = len(baseline_results_df)\n",
    "\n",
    "ac = accuracy_score(text_test['label'], majority_class)\n",
    "pr = precision_score(text_test['label'], majority_class)\n",
    "roc = roc_auc_score(text_test['label'], majority_class)\n",
    "\n",
    "baseline_results_df.loc[count, 'Model:'] = 'Naive Majority Class Classifier'\n",
    "baseline_results_df.loc[count, 'Accuracy:'] = ac\n",
    "baseline_results_df.loc[count, 'Precision:'] = pr\n",
    "baseline_results_df.loc[count, 'ROC:'] = roc\n",
    "\n",
    "cols = ['Model:', 'Accuracy:', 'Precision:', 'ROC:']\n",
    "\n",
    "baseline_results_df = baseline_results_df[cols]\n",
    "baseline_results_df.head(len(baseline_results_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "to_shuffle = True\n",
    "n_batch = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original CNN (Model 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:526: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:788: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 2746 samples, validate on 1177 samples\n",
      "Epoch 1/5\n",
      "2746/2746 [==============================] - 23s 8ms/step - loss: 0.4049 - acc: 0.8281 - keras_precision: 0.8281 - keras_recall: 0.8281 - keras_auc: 0.8646 - val_loss: 0.3230 - val_acc: 0.8598 - val_keras_precision: 0.8598 - val_keras_recall: 0.8598 - val_keras_auc: 0.9052\n",
      "Epoch 2/5\n",
      "2746/2746 [==============================] - 25s 9ms/step - loss: 0.2607 - acc: 0.8973 - keras_precision: 0.8973 - keras_recall: 0.8973 - keras_auc: 0.9235 - val_loss: 0.3795 - val_acc: 0.8437 - val_keras_precision: 0.8437 - val_keras_recall: 0.8437 - val_keras_auc: 0.9315\n",
      "Epoch 3/5\n",
      "2746/2746 [==============================] - 25s 9ms/step - loss: 0.1910 - acc: 0.9312 - keras_precision: 0.9312 - keras_recall: 0.9312 - keras_auc: 0.9382 - val_loss: 0.3406 - val_acc: 0.8641 - val_keras_precision: 0.8641 - val_keras_recall: 0.8641 - val_keras_auc: 0.9445\n",
      "Epoch 4/5\n",
      "2746/2746 [==============================] - 25s 9ms/step - loss: 0.1276 - acc: 0.9538 - keras_precision: 0.9538 - keras_recall: 0.9538 - keras_auc: 0.9506 - val_loss: 0.3878 - val_acc: 0.8624 - val_keras_precision: 0.8624 - val_keras_recall: 0.8624 - val_keras_auc: 0.9542\n",
      "Epoch 5/5\n",
      "2746/2746 [==============================] - 21s 8ms/step - loss: 0.0725 - acc: 0.9752 - keras_precision: 0.9752 - keras_recall: 0.9752 - keras_auc: 0.9581 - val_loss: 0.4860 - val_acc: 0.8539 - val_keras_precision: 0.8539 - val_keras_recall: 0.8539 - val_keras_auc: 0.9608\n"
     ]
    }
   ],
   "source": [
    "cnn_1 = Sequential()\n",
    "cnn_1.add(Embedding(vocabulary_size, 100, input_length=maxlen))\n",
    "cnn_1.add(Dropout(0.2))\n",
    "cnn_1.add(Conv1D(64, 5, activation='relu'))\n",
    "cnn_1.add(MaxPooling1D(pool_size=4))\n",
    "cnn_1.add(LSTM(100))\n",
    "cnn_1.add(Dense(2, activation='softmax'))\n",
    "cnn_1.compile(loss='binary_crossentropy', \n",
    "               optimizer='adam', \n",
    "                metrics=['accuracy', \n",
    "                    custom_keras_metrics.keras_precision, \n",
    "                    custom_keras_metrics.keras_recall, \n",
    "                    custom_keras_metrics.keras_auc])\n",
    "\n",
    "fit_cnn_1 = cnn_1.fit(text_train[new_col_names], \n",
    "                  label_train, \n",
    "                  validation_data=(text_test[new_col_names],label_test), \n",
    "                  epochs=n_epochs,\n",
    "                  shuffle=to_shuffle,\n",
    "                  batch_size=3)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 2 - Without LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2746 samples, validate on 1177 samples\n",
      "Epoch 1/5\n",
      "2746/2746 [==============================] - 5s 2ms/step - loss: 0.4226 - acc: 0.8186 - keras_precision: 0.8186 - keras_recall: 0.8186 - keras_auc: 0.8405 - val_loss: 0.3259 - val_acc: 0.8709 - val_keras_precision: 0.8709 - val_keras_recall: 0.8709 - val_keras_auc: 0.8974\n",
      "Epoch 2/5\n",
      "2746/2746 [==============================] - 4s 1ms/step - loss: 0.2454 - acc: 0.9024 - keras_precision: 0.9024 - keras_recall: 0.9024 - keras_auc: 0.9219 - val_loss: 0.3491 - val_acc: 0.8666 - val_keras_precision: 0.8666 - val_keras_recall: 0.8666 - val_keras_auc: 0.9322\n",
      "Epoch 3/5\n",
      "2746/2746 [==============================] - 4s 1ms/step - loss: 0.1434 - acc: 0.9465 - keras_precision: 0.9465 - keras_recall: 0.9465 - keras_auc: 0.9418 - val_loss: 0.4155 - val_acc: 0.8632 - val_keras_precision: 0.8632 - val_keras_recall: 0.8632 - val_keras_auc: 0.9485\n",
      "Epoch 4/5\n",
      "2746/2746 [==============================] - 3s 1ms/step - loss: 0.0709 - acc: 0.9745 - keras_precision: 0.9745 - keras_recall: 0.9745 - keras_auc: 0.9541 - val_loss: 0.4771 - val_acc: 0.8649 - val_keras_precision: 0.8649 - val_keras_recall: 0.8649 - val_keras_auc: 0.9587\n",
      "Epoch 5/5\n",
      "2746/2746 [==============================] - 3s 1ms/step - loss: 0.0421 - acc: 0.9894 - keras_precision: 0.9894 - keras_recall: 0.9894 - keras_auc: 0.9617 - val_loss: 0.5767 - val_acc: 0.8539 - val_keras_precision: 0.8539 - val_keras_recall: 0.8539 - val_keras_auc: 0.9642\n"
     ]
    }
   ],
   "source": [
    "cnn_2 = Sequential()\n",
    "cnn_2.add(Embedding(vocabulary_size, 100, input_length=maxlen))\n",
    "cnn_2.add(Dropout(0.2))\n",
    "cnn_2.add(Conv1D(64, 5, activation='relu'))\n",
    "cnn_2.add(MaxPooling1D(pool_size=4))\n",
    "cnn_2.add(Flatten())\n",
    "cnn_2.add(Dense(2, activation='softmax'))\n",
    "cnn_2.compile(loss='binary_crossentropy', \n",
    "               optimizer='adam', \n",
    "                metrics=['accuracy', \n",
    "                    custom_keras_metrics.keras_precision, \n",
    "                    custom_keras_metrics.keras_recall, \n",
    "                    custom_keras_metrics.keras_auc])\n",
    "\n",
    "fit_cnn_2 = cnn_2.fit(text_train[new_col_names], \n",
    "                  label_train, \n",
    "                  validation_data=(text_test[new_col_names],label_test), \n",
    "                  epochs=n_epochs,\n",
    "                  shuffle=to_shuffle,\n",
    "                  batch_size=n_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 3 - LSTM without Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2746 samples, validate on 1177 samples\n",
      "Epoch 1/5\n",
      "2746/2746 [==============================] - 85s 31ms/step - loss: 0.4323 - acc: 0.8179 - keras_precision: 0.8179 - keras_recall: 0.8179 - keras_auc: 0.8437 - val_loss: 0.3368 - val_acc: 0.8649 - val_keras_precision: 0.8649 - val_keras_recall: 0.8649 - val_keras_auc: 0.8918\n",
      "Epoch 2/5\n",
      "2746/2746 [==============================] - 72s 26ms/step - loss: 0.2897 - acc: 0.8827 - keras_precision: 0.8827 - keras_recall: 0.8827 - keras_auc: 0.9124 - val_loss: 0.3339 - val_acc: 0.8590 - val_keras_precision: 0.8590 - val_keras_recall: 0.8590 - val_keras_auc: 0.9225\n",
      "Epoch 3/5\n",
      "2746/2746 [==============================] - 77s 28ms/step - loss: 0.2312 - acc: 0.9093 - keras_precision: 0.9093 - keras_recall: 0.9093 - keras_auc: 0.9313 - val_loss: 0.3461 - val_acc: 0.8522 - val_keras_precision: 0.8522 - val_keras_recall: 0.8522 - val_keras_auc: 0.9363\n",
      "Epoch 4/5\n",
      "2746/2746 [==============================] - 78s 28ms/step - loss: 0.1816 - acc: 0.9381 - keras_precision: 0.9381 - keras_recall: 0.9381 - keras_auc: 0.9415 - val_loss: 0.3632 - val_acc: 0.8641 - val_keras_precision: 0.8641 - val_keras_recall: 0.8641 - val_keras_auc: 0.9452\n",
      "Epoch 5/5\n",
      "2746/2746 [==============================] - 77s 28ms/step - loss: 0.1514 - acc: 0.9428 - keras_precision: 0.9428 - keras_recall: 0.9428 - keras_auc: 0.9490 - val_loss: 0.4057 - val_acc: 0.8479 - val_keras_precision: 0.8479 - val_keras_recall: 0.8479 - val_keras_auc: 0.9511\n"
     ]
    }
   ],
   "source": [
    "cnn_3 = Sequential()\n",
    "cnn_3.add(Embedding(vocabulary_size, 100, input_length=maxlen))\n",
    "cnn_3.add(Dropout(0.2))\n",
    "cnn_3.add(LSTM(100))\n",
    "cnn_3.add(Dense(2, activation='softmax'))\n",
    "cnn_3.compile(loss='binary_crossentropy', \n",
    "               optimizer='adam', \n",
    "                metrics=['accuracy', \n",
    "                    custom_keras_metrics.keras_precision, \n",
    "                    custom_keras_metrics.keras_recall, \n",
    "                    custom_keras_metrics.keras_auc])\n",
    "\n",
    "fit_cnn_3 = cnn_3.fit(text_train[new_col_names], \n",
    "                  label_train, \n",
    "                  validation_data=(text_test[new_col_names],label_test), \n",
    "                  epochs=n_epochs,\n",
    "                  shuffle=to_shuffle,\n",
    "                  batch_size=n_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2746 samples, validate on 1177 samples\n",
      "Epoch 1/5\n",
      "2746/2746 [==============================] - 4s 1ms/step - loss: 0.5333 - acc: 0.7775 - keras_precision: 0.7775 - keras_recall: 0.7775 - keras_auc: 0.7662 - val_loss: 0.5303 - val_acc: 0.7774 - val_keras_precision: 0.7774 - val_keras_recall: 0.7774 - val_keras_auc: 0.7739\n",
      "Epoch 2/5\n",
      "2746/2746 [==============================] - 4s 1ms/step - loss: 0.5307 - acc: 0.7775 - keras_precision: 0.7775 - keras_recall: 0.7775 - keras_auc: 0.7744 - val_loss: 0.5301 - val_acc: 0.7774 - val_keras_precision: 0.7774 - val_keras_recall: 0.7774 - val_keras_auc: 0.7738\n",
      "Epoch 3/5\n",
      "2746/2746 [==============================] - 3s 1ms/step - loss: 0.5304 - acc: 0.7775 - keras_precision: 0.7775 - keras_recall: 0.7775 - keras_auc: 0.7733 - val_loss: 0.5301 - val_acc: 0.7774 - val_keras_precision: 0.7774 - val_keras_recall: 0.7774 - val_keras_auc: 0.7741\n",
      "Epoch 4/5\n",
      "2746/2746 [==============================] - 4s 1ms/step - loss: 0.5302 - acc: 0.7775 - keras_precision: 0.7775 - keras_recall: 0.7775 - keras_auc: 0.7742 - val_loss: 0.5301 - val_acc: 0.7774 - val_keras_precision: 0.7774 - val_keras_recall: 0.7774 - val_keras_auc: 0.7752\n",
      "Epoch 5/5\n",
      "2746/2746 [==============================] - 4s 1ms/step - loss: 0.5298 - acc: 0.7775 - keras_precision: 0.7775 - keras_recall: 0.7775 - keras_auc: 0.7762 - val_loss: 0.5301 - val_acc: 0.7774 - val_keras_precision: 0.7774 - val_keras_recall: 0.7774 - val_keras_auc: 0.7764\n"
     ]
    }
   ],
   "source": [
    "dim = text_train[new_col_names].shape[1]\n",
    "\n",
    "auto_encoder_1 = Sequential()\n",
    "auto_encoder_1.add(Dense(units=100, activation='relu', input_dim=dim))\n",
    "auto_encoder_1.add(Dense(units=500, activation='softmax'))\n",
    "auto_encoder_1.add(Dense(units=10, activation='softmax'))\n",
    "auto_encoder_1.add(Dense(units=1000, activation='relu'))\n",
    "auto_encoder_1.add(Dense(units=500, activation='relu'))\n",
    "auto_encoder_1.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "auto_encoder_1.compile(loss='binary_crossentropy',\n",
    "              optimizer=keras.optimizers.Adagrad(lr=0.001), \n",
    "              metrics=['accuracy', \n",
    "                       custom_keras_metrics.keras_precision, \n",
    "                       custom_keras_metrics.keras_recall, \n",
    "                       custom_keras_metrics.keras_auc])\n",
    "\n",
    "fit_auto_encoder_1 = auto_encoder_1.fit(text_train[new_col_names], \n",
    "                  label_train, \n",
    "                  validation_data=(text_test[new_col_names],label_test), \n",
    "                epochs=n_epochs,\n",
    "                batch_size=n_batch,\n",
    "                shuffle=to_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_1.name = \"cnn_1\"\n",
    "cnn_2.name = \"cnn_2\"\n",
    "cnn_3.name = \"cnn_3\"\n",
    "auto_encoder_1.name = \"auto_encoder_1\"\n",
    "ann_models = [cnn_1, cnn_2, cnn_3, auto_encoder_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################## cnn_1 ##########################\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 100)          100000    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 96, 64)            32064     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 24, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               66000     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 198,266\n",
      "Trainable params: 198,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "########################## cnn_2 ##########################\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 100, 100)          100000    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 96, 64)            32064     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 24, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 3074      \n",
      "=================================================================\n",
      "Total params: 135,138\n",
      "Trainable params: 135,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "########################## cnn_3 ##########################\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 100)          100000    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 180,602\n",
      "Trainable params: 180,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "########################## auto_encoder_1 ##########################\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 500)               50500     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5010      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1000)              11000     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 1002      \n",
      "=================================================================\n",
      "Total params: 578,112\n",
      "Trainable params: 578,112\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for model in ann_models:\n",
    "    print(\"##########################\", model.name, \"##########################\")\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: fix results table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "      <td>cnn_1</td>\n",
       "      <td>0.486026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>val_acc</td>\n",
       "      <td>cnn_1</td>\n",
       "      <td>0.853866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>val_keras_precision</td>\n",
       "      <td>cnn_1</td>\n",
       "      <td>0.853866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>val_keras_recall</td>\n",
       "      <td>cnn_1</td>\n",
       "      <td>0.853866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>val_keras_auc</td>\n",
       "      <td>cnn_1</td>\n",
       "      <td>0.960798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>loss</td>\n",
       "      <td>cnn_1</td>\n",
       "      <td>0.072545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>acc</td>\n",
       "      <td>cnn_1</td>\n",
       "      <td>0.975237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>keras_precision</td>\n",
       "      <td>cnn_1</td>\n",
       "      <td>0.975237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>keras_recall</td>\n",
       "      <td>cnn_1</td>\n",
       "      <td>0.975237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>keras_auc</td>\n",
       "      <td>cnn_1</td>\n",
       "      <td>0.958070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "      <td>cnn_2</td>\n",
       "      <td>0.576744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>val_acc</td>\n",
       "      <td>cnn_2</td>\n",
       "      <td>0.853866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>val_keras_precision</td>\n",
       "      <td>cnn_2</td>\n",
       "      <td>0.853866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>val_keras_recall</td>\n",
       "      <td>cnn_2</td>\n",
       "      <td>0.853866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>val_keras_auc</td>\n",
       "      <td>cnn_2</td>\n",
       "      <td>0.964199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>loss</td>\n",
       "      <td>cnn_2</td>\n",
       "      <td>0.042143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>acc</td>\n",
       "      <td>cnn_2</td>\n",
       "      <td>0.989439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>keras_precision</td>\n",
       "      <td>cnn_2</td>\n",
       "      <td>0.989439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>keras_recall</td>\n",
       "      <td>cnn_2</td>\n",
       "      <td>0.989439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>keras_auc</td>\n",
       "      <td>cnn_2</td>\n",
       "      <td>0.961704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "      <td>cnn_3</td>\n",
       "      <td>0.405682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5</td>\n",
       "      <td>val_acc</td>\n",
       "      <td>cnn_3</td>\n",
       "      <td>0.847918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5</td>\n",
       "      <td>val_keras_precision</td>\n",
       "      <td>cnn_3</td>\n",
       "      <td>0.847918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "      <td>val_keras_recall</td>\n",
       "      <td>cnn_3</td>\n",
       "      <td>0.847918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5</td>\n",
       "      <td>val_keras_auc</td>\n",
       "      <td>cnn_3</td>\n",
       "      <td>0.951130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>loss</td>\n",
       "      <td>cnn_3</td>\n",
       "      <td>0.151449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5</td>\n",
       "      <td>acc</td>\n",
       "      <td>cnn_3</td>\n",
       "      <td>0.942826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5</td>\n",
       "      <td>keras_precision</td>\n",
       "      <td>cnn_3</td>\n",
       "      <td>0.942826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>keras_recall</td>\n",
       "      <td>cnn_3</td>\n",
       "      <td>0.942826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>keras_auc</td>\n",
       "      <td>cnn_3</td>\n",
       "      <td>0.948967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "      <td>auto_encoder_1</td>\n",
       "      <td>0.530059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>val_acc</td>\n",
       "      <td>auto_encoder_1</td>\n",
       "      <td>0.777400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>val_keras_precision</td>\n",
       "      <td>auto_encoder_1</td>\n",
       "      <td>0.777400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>val_keras_recall</td>\n",
       "      <td>auto_encoder_1</td>\n",
       "      <td>0.777400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>5</td>\n",
       "      <td>val_keras_auc</td>\n",
       "      <td>auto_encoder_1</td>\n",
       "      <td>0.776383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5</td>\n",
       "      <td>loss</td>\n",
       "      <td>auto_encoder_1</td>\n",
       "      <td>0.529838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5</td>\n",
       "      <td>acc</td>\n",
       "      <td>auto_encoder_1</td>\n",
       "      <td>0.777495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5</td>\n",
       "      <td>keras_precision</td>\n",
       "      <td>auto_encoder_1</td>\n",
       "      <td>0.777495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5</td>\n",
       "      <td>keras_recall</td>\n",
       "      <td>auto_encoder_1</td>\n",
       "      <td>0.777495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>5</td>\n",
       "      <td>keras_auc</td>\n",
       "      <td>auto_encoder_1</td>\n",
       "      <td>0.776209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch               metric           model     value\n",
       "0       5             val_loss           cnn_1  0.486026\n",
       "1       5              val_acc           cnn_1  0.853866\n",
       "2       5  val_keras_precision           cnn_1  0.853866\n",
       "3       5     val_keras_recall           cnn_1  0.853866\n",
       "4       5        val_keras_auc           cnn_1  0.960798\n",
       "5       5                 loss           cnn_1  0.072545\n",
       "6       5                  acc           cnn_1  0.975237\n",
       "7       5      keras_precision           cnn_1  0.975237\n",
       "8       5         keras_recall           cnn_1  0.975237\n",
       "9       5            keras_auc           cnn_1  0.958070\n",
       "10      5             val_loss           cnn_2  0.576744\n",
       "11      5              val_acc           cnn_2  0.853866\n",
       "12      5  val_keras_precision           cnn_2  0.853866\n",
       "13      5     val_keras_recall           cnn_2  0.853866\n",
       "14      5        val_keras_auc           cnn_2  0.964199\n",
       "15      5                 loss           cnn_2  0.042143\n",
       "16      5                  acc           cnn_2  0.989439\n",
       "17      5      keras_precision           cnn_2  0.989439\n",
       "18      5         keras_recall           cnn_2  0.989439\n",
       "19      5            keras_auc           cnn_2  0.961704\n",
       "20      5             val_loss           cnn_3  0.405682\n",
       "21      5              val_acc           cnn_3  0.847918\n",
       "22      5  val_keras_precision           cnn_3  0.847918\n",
       "23      5     val_keras_recall           cnn_3  0.847918\n",
       "24      5        val_keras_auc           cnn_3  0.951130\n",
       "25      5                 loss           cnn_3  0.151449\n",
       "26      5                  acc           cnn_3  0.942826\n",
       "27      5      keras_precision           cnn_3  0.942826\n",
       "28      5         keras_recall           cnn_3  0.942826\n",
       "29      5            keras_auc           cnn_3  0.948967\n",
       "30      5             val_loss  auto_encoder_1  0.530059\n",
       "31      1              val_acc  auto_encoder_1  0.777400\n",
       "32      1  val_keras_precision  auto_encoder_1  0.777400\n",
       "33      1     val_keras_recall  auto_encoder_1  0.777400\n",
       "34      5        val_keras_auc  auto_encoder_1  0.776383\n",
       "35      5                 loss  auto_encoder_1  0.529838\n",
       "36      5                  acc  auto_encoder_1  0.777495\n",
       "37      5      keras_precision  auto_encoder_1  0.777495\n",
       "38      5         keras_recall  auto_encoder_1  0.777495\n",
       "39      5            keras_auc  auto_encoder_1  0.776209"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rows = []\n",
    "\n",
    "for model in ann_models:        \n",
    "    for metric_key, values in model.history.history.items():\n",
    "        for value in values: # each epoch\n",
    "            \n",
    "            row = {\"model\": model.name, \n",
    "                   \"epoch\":values.index(value) + 1,\n",
    "                  \"metric\":metric_key, \n",
    "                  \"value\":value, }\n",
    "        new_rows.append(row)\n",
    "        \n",
    "        \n",
    "ann_results_df = pd.DataFrame(new_rows)\n",
    "ann_results_df.head(len(ann_results_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "      <td>cnn_1</td>\n",
       "      <td>0.486026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>val_acc</td>\n",
       "      <td>cnn_1</td>\n",
       "      <td>0.853866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>val_keras_precision</td>\n",
       "      <td>cnn_1</td>\n",
       "      <td>0.853866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>val_keras_recall</td>\n",
       "      <td>cnn_1</td>\n",
       "      <td>0.853866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5</td>\n",
       "      <td>val_keras_auc</td>\n",
       "      <td>cnn_1</td>\n",
       "      <td>0.960798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>loss</td>\n",
       "      <td>cnn_1</td>\n",
       "      <td>0.072545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>5</td>\n",
       "      <td>acc</td>\n",
       "      <td>cnn_1</td>\n",
       "      <td>0.975237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>5</td>\n",
       "      <td>keras_precision</td>\n",
       "      <td>cnn_1</td>\n",
       "      <td>0.975237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5</td>\n",
       "      <td>keras_recall</td>\n",
       "      <td>cnn_1</td>\n",
       "      <td>0.975237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5</td>\n",
       "      <td>keras_auc</td>\n",
       "      <td>cnn_1</td>\n",
       "      <td>0.958070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "      <td>cnn_2</td>\n",
       "      <td>0.576744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>5</td>\n",
       "      <td>val_acc</td>\n",
       "      <td>cnn_2</td>\n",
       "      <td>0.853866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>5</td>\n",
       "      <td>val_keras_precision</td>\n",
       "      <td>cnn_2</td>\n",
       "      <td>0.853866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>5</td>\n",
       "      <td>val_keras_recall</td>\n",
       "      <td>cnn_2</td>\n",
       "      <td>0.853866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>5</td>\n",
       "      <td>val_keras_auc</td>\n",
       "      <td>cnn_2</td>\n",
       "      <td>0.964199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>5</td>\n",
       "      <td>loss</td>\n",
       "      <td>cnn_2</td>\n",
       "      <td>0.042143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>5</td>\n",
       "      <td>acc</td>\n",
       "      <td>cnn_2</td>\n",
       "      <td>0.989439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>5</td>\n",
       "      <td>keras_precision</td>\n",
       "      <td>cnn_2</td>\n",
       "      <td>0.989439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5</td>\n",
       "      <td>keras_recall</td>\n",
       "      <td>cnn_2</td>\n",
       "      <td>0.989439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>keras_auc</td>\n",
       "      <td>cnn_2</td>\n",
       "      <td>0.961704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "      <td>cnn_3</td>\n",
       "      <td>0.405682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>5</td>\n",
       "      <td>val_acc</td>\n",
       "      <td>cnn_3</td>\n",
       "      <td>0.847918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>5</td>\n",
       "      <td>val_keras_precision</td>\n",
       "      <td>cnn_3</td>\n",
       "      <td>0.847918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>5</td>\n",
       "      <td>val_keras_recall</td>\n",
       "      <td>cnn_3</td>\n",
       "      <td>0.847918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>5</td>\n",
       "      <td>val_keras_auc</td>\n",
       "      <td>cnn_3</td>\n",
       "      <td>0.951130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>5</td>\n",
       "      <td>loss</td>\n",
       "      <td>cnn_3</td>\n",
       "      <td>0.151449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>5</td>\n",
       "      <td>acc</td>\n",
       "      <td>cnn_3</td>\n",
       "      <td>0.942826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>5</td>\n",
       "      <td>keras_precision</td>\n",
       "      <td>cnn_3</td>\n",
       "      <td>0.942826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>5</td>\n",
       "      <td>keras_recall</td>\n",
       "      <td>cnn_3</td>\n",
       "      <td>0.942826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5</td>\n",
       "      <td>keras_auc</td>\n",
       "      <td>cnn_3</td>\n",
       "      <td>0.948967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "      <td>auto_encoder_1</td>\n",
       "      <td>0.530059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>5</td>\n",
       "      <td>val_acc</td>\n",
       "      <td>auto_encoder_1</td>\n",
       "      <td>0.777400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>5</td>\n",
       "      <td>val_keras_precision</td>\n",
       "      <td>auto_encoder_1</td>\n",
       "      <td>0.777400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>5</td>\n",
       "      <td>val_keras_recall</td>\n",
       "      <td>auto_encoder_1</td>\n",
       "      <td>0.777400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>5</td>\n",
       "      <td>val_keras_auc</td>\n",
       "      <td>auto_encoder_1</td>\n",
       "      <td>0.776383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>5</td>\n",
       "      <td>loss</td>\n",
       "      <td>auto_encoder_1</td>\n",
       "      <td>0.529838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>5</td>\n",
       "      <td>acc</td>\n",
       "      <td>auto_encoder_1</td>\n",
       "      <td>0.777495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>5</td>\n",
       "      <td>keras_precision</td>\n",
       "      <td>auto_encoder_1</td>\n",
       "      <td>0.777495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>5</td>\n",
       "      <td>keras_recall</td>\n",
       "      <td>auto_encoder_1</td>\n",
       "      <td>0.777495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>5</td>\n",
       "      <td>keras_auc</td>\n",
       "      <td>auto_encoder_1</td>\n",
       "      <td>0.776209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch               metric           model     value\n",
       "4       5             val_loss           cnn_1  0.486026\n",
       "9       5              val_acc           cnn_1  0.853866\n",
       "14      5  val_keras_precision           cnn_1  0.853866\n",
       "19      5     val_keras_recall           cnn_1  0.853866\n",
       "24      5        val_keras_auc           cnn_1  0.960798\n",
       "29      5                 loss           cnn_1  0.072545\n",
       "34      5                  acc           cnn_1  0.975237\n",
       "39      5      keras_precision           cnn_1  0.975237\n",
       "44      5         keras_recall           cnn_1  0.975237\n",
       "49      5            keras_auc           cnn_1  0.958070\n",
       "54      5             val_loss           cnn_2  0.576744\n",
       "59      5              val_acc           cnn_2  0.853866\n",
       "64      5  val_keras_precision           cnn_2  0.853866\n",
       "69      5     val_keras_recall           cnn_2  0.853866\n",
       "74      5        val_keras_auc           cnn_2  0.964199\n",
       "79      5                 loss           cnn_2  0.042143\n",
       "84      5                  acc           cnn_2  0.989439\n",
       "89      5      keras_precision           cnn_2  0.989439\n",
       "94      5         keras_recall           cnn_2  0.989439\n",
       "99      5            keras_auc           cnn_2  0.961704\n",
       "104     5             val_loss           cnn_3  0.405682\n",
       "109     5              val_acc           cnn_3  0.847918\n",
       "114     5  val_keras_precision           cnn_3  0.847918\n",
       "119     5     val_keras_recall           cnn_3  0.847918\n",
       "124     5        val_keras_auc           cnn_3  0.951130\n",
       "129     5                 loss           cnn_3  0.151449\n",
       "134     5                  acc           cnn_3  0.942826\n",
       "139     5      keras_precision           cnn_3  0.942826\n",
       "144     5         keras_recall           cnn_3  0.942826\n",
       "149     5            keras_auc           cnn_3  0.948967\n",
       "154     5             val_loss  auto_encoder_1  0.530059\n",
       "159     5              val_acc  auto_encoder_1  0.777400\n",
       "164     5  val_keras_precision  auto_encoder_1  0.777400\n",
       "169     5     val_keras_recall  auto_encoder_1  0.777400\n",
       "174     5        val_keras_auc  auto_encoder_1  0.776383\n",
       "179     5                 loss  auto_encoder_1  0.529838\n",
       "184     5                  acc  auto_encoder_1  0.777495\n",
       "189     5      keras_precision  auto_encoder_1  0.777495\n",
       "194     5         keras_recall  auto_encoder_1  0.777495\n",
       "199     5            keras_auc  auto_encoder_1  0.776209"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_epoch = ann_results_df.loc[ann_results_df['epoch'] == '5']\n",
    "last_epoch.head(len(last_epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Prections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation</th>\n",
       "      <th>fileID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>1</td>\n",
       "      <td>a copy of this entire consent form will be giv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NON_permission_statement</td>\n",
       "      <td>1</td>\n",
       "      <td>\"what if i change my mind about participating ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NON_permission_statement</td>\n",
       "      <td>1</td>\n",
       "      <td>ask your study doctor for more information abo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NON_permission_statement</td>\n",
       "      <td>1</td>\n",
       "      <td>newborn screening required additional language...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NON_permission_statement</td>\n",
       "      <td>1</td>\n",
       "      <td>\"if you are a healthy volunteer, no direct med...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  annotation fileID  \\\n",
       "0  NON_permission_statement.      1   \n",
       "1   NON_permission_statement      1   \n",
       "2   NON_permission_statement      1   \n",
       "3   NON_permission_statement      1   \n",
       "4   NON_permission_statement      1   \n",
       "\n",
       "                                                text  \n",
       "0  a copy of this entire consent form will be giv...  \n",
       "1  \"what if i change my mind about participating ...  \n",
       "2  ask your study doctor for more information abo...  \n",
       "3  newborn screening required additional language...  \n",
       "4  \"if you are a healthy volunteer, no direct med...  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data ='../data/ALL_CANDIDATES.json'\n",
    "pred_df = load_data.getJSONData(full_data)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 1000\n",
    "maxlen = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "tokenizer.fit_on_texts(pred_df['text'])\n",
    "sequences = tokenizer.texts_to_sequences(pred_df['text'])\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "pred_df['data'] = data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col_names = ['seq_posi' + str(i) for i in range(0,maxlen)]\n",
    "pos_seq_df = pd.DataFrame(pred_df['data'].values.tolist(), columns=new_col_names)\n",
    "pred_df = pd.concat([pred_df, pos_seq_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cnn_1.predict_classes(pred_df[new_col_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Positive Predictions: 3882\n",
      "Number of Cases: 20000\n",
      "Percentage Predicted Positive:  0.1941\n"
     ]
    }
   ],
   "source": [
    "print('Total Positive Predictions:', sum(predictions))\n",
    "print('Number of Cases:', len(predictions))\n",
    "print('Percentage Predicted Positive: ', sum(predictions)/len(predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'predictions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2601\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2602\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2603\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'predictions'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-15e068a228c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpositives_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predictions'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2915\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2916\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2917\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2918\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2919\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2602\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2603\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2604\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2605\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2606\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'predictions'"
     ]
    }
   ],
   "source": [
    "positives_df = df.loc[df['predictions'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'positives_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-44a25e4550e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpositives_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fileID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'positives_df' is not defined"
     ]
    }
   ],
   "source": [
    "for idx, row in positives_df.head(10).iterrows():\n",
    "    print(row['fileID'], row['text'], '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
